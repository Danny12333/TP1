{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8404be25",
   "metadata": {},
   "source": [
    "## Daniel Joaquim Paulino\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TP1  using library :   Hugging face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099816f6",
   "metadata": {},
   "source": [
    "# Text to Tokenize in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14bc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#THIS IS OUR TEXT TO TOKENIZE IN ENGLISH : \n",
      "            Perhaps one of the most significant advances made by Arabic mathematics began at this time \n",
      "            with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to \n",
      "            understand just how significant this new idea was. It was a revolutionary move away \n",
      "            from the Greek concept of mathematics which was essentially geometry. Algebra was a \n",
      "            unifying theory which allowed rational numbers, irrational numbers, geometrical \n",
      "            magnitudes,etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
      "            development path so much broader in concept to that which had existed before, and provided a\n",
      "            vehicle for future development of the subject. Another important aspect of the introduction \n",
      "            of algebraic ideas was that it allowed mathematics to be applied to itself in a way which \n",
      "            had not happened before.\n"
     ]
    }
   ],
   "source": [
    "english_text=(\"\"\"\n",
    "            Perhaps one of the most significant advances made by Arabic mathematics began at this time \n",
    "            with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to \n",
    "            understand just how significant this new idea was. It was a revolutionary move away \n",
    "            from the Greek concept of mathematics which was essentially geometry. Algebra was a \n",
    "            unifying theory which allowed rational numbers, irrational numbers, geometrical \n",
    "            magnitudes,etc., to all be treated as \"algebraic objects\". It gave mathematics a whole new \n",
    "            development path so much broader in concept to that which had existed before, and provided a\n",
    "            vehicle for future development of the subject. Another important aspect of the introduction \n",
    "            of algebraic ideas was that it allowed mathematics to be applied to itself in a way which \n",
    "            had not happened before.\"\"\")\n",
    "print(\"#THIS IS OUR TEXT TO TOKENIZE IN ENGLISH :\",english_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67b5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers\n",
    "#pip install flair\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50689fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#RESULT OF TOKENIZE:  ['perhaps', 'one', 'of', 'the', 'most', 'significant', 'advances', 'made', 'by', 'arabic', 'mathematics', 'began', 'at', 'this', 'time', 'with', 'the', 'work', 'of', 'al', '-', 'k', '##hwa', '##riz', '##mi', ',', 'namely', 'the', 'beginnings', 'of', 'algebra', '.', 'it', 'is', 'important', 'to', 'understand', 'just', 'how', 'significant', 'this', 'new', 'idea', 'was', '.', 'it', 'was', 'a', 'revolutionary', 'move', 'away', 'from', 'the', 'greek', 'concept', 'of', 'mathematics', 'which', 'was', 'essentially', 'geometry', '.', 'algebra', 'was', 'a', 'un', '##ifying', 'theory', 'which', 'allowed', 'rational', 'numbers', ',', 'irrational', 'numbers', ',', 'geometric', '##al', 'magnitude', '##s', ',', 'etc', '.', ',', 'to', 'all', 'be', 'treated', 'as', '\"', 'algebraic', 'objects', '\"', '.', 'it', 'gave', 'mathematics', 'a', 'whole', 'new', 'development', 'path', 'so', 'much', 'broader', 'in', 'concept', 'to', 'that', 'which', 'had', 'existed', 'before', ',', 'and', 'provided', 'a', 'vehicle', 'for', 'future', 'development', 'of', 'the', 'subject', '.', 'another', 'important', 'aspect', 'of', 'the', 'introduction', 'of', 'algebraic', 'ideas', 'was', 'that', 'it', 'allowed', 'mathematics', 'to', 'be', 'applied', 'to', 'itself', 'in', 'a', 'way', 'which', 'had', 'not', 'happened', 'before', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "token=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token1=token.tokenize(english_text)\n",
    "\n",
    "#PRINT OF TOKENIZE\n",
    "\n",
    "print(\"#RESULT OF TOKENIZE: \",token1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5b7c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-20 21:45:05,223 loading file /Users/danieljoaquimpaulino/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
      "Span [1]: \"Perhaps\"   [− Labels: RB (1.0)]\n",
      "Span [2]: \"one\"   [− Labels: CD (0.9999)]\n",
      "Span [3]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [4]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [5]: \"most\"   [− Labels: RBS (0.9999)]\n",
      "Span [6]: \"significant\"   [− Labels: JJ (1.0)]\n",
      "Span [7]: \"advances\"   [− Labels: NNS (1.0)]\n",
      "Span [8]: \"made\"   [− Labels: VBN (1.0)]\n",
      "Span [9]: \"by\"   [− Labels: IN (1.0)]\n",
      "Span [10]: \"Arabic\"   [− Labels: JJ (0.9997)]\n",
      "Span [11]: \"mathematics\"   [− Labels: NNS (0.9996)]\n",
      "Span [12]: \"began\"   [− Labels: VBD (1.0)]\n",
      "Span [13]: \"at\"   [− Labels: IN (1.0)]\n",
      "Span [14]: \"this\"   [− Labels: DT (1.0)]\n",
      "Span [15]: \"time\"   [− Labels: NN (1.0)]\n",
      "Span [16]: \"with\"   [− Labels: IN (1.0)]\n",
      "Span [17]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [18]: \"work\"   [− Labels: NN (1.0)]\n",
      "Span [19]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [20]: \"al-Khwarizmi\"   [− Labels: NNP (0.9996)]\n",
      "Span [21]: \",\"   [− Labels: , (1.0)]\n",
      "Span [22]: \"namely\"   [− Labels: RB (1.0)]\n",
      "Span [23]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [24]: \"beginnings\"   [− Labels: NNS (1.0)]\n",
      "Span [25]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [26]: \"algebra\"   [− Labels: NN (0.9841)]\n",
      "Span [27]: \".\"   [− Labels: , (0.9918)]\n",
      "Span [28]: \"It\"   [− Labels: PRP (1.0)]\n",
      "Span [29]: \"is\"   [− Labels: VBZ (1.0)]\n",
      "Span [30]: \"important\"   [− Labels: JJ (1.0)]\n",
      "Span [31]: \"to\"   [− Labels: TO (1.0)]\n",
      "Span [32]: \"understand\"   [− Labels: VB (1.0)]\n",
      "Span [33]: \"just\"   [− Labels: RB (0.9998)]\n",
      "Span [34]: \"how\"   [− Labels: WRB (1.0)]\n",
      "Span [35]: \"significant\"   [− Labels: JJ (1.0)]\n",
      "Span [36]: \"this\"   [− Labels: DT (1.0)]\n",
      "Span [37]: \"new\"   [− Labels: JJ (1.0)]\n",
      "Span [38]: \"idea\"   [− Labels: NN (1.0)]\n",
      "Span [39]: \"was\"   [− Labels: VBD (1.0)]\n",
      "Span [40]: \".\"   [− Labels: , (0.9986)]\n",
      "Span [41]: \"It\"   [− Labels: PRP (1.0)]\n",
      "Span [42]: \"was\"   [− Labels: VBD (1.0)]\n",
      "Span [43]: \"a\"   [− Labels: DT (1.0)]\n",
      "Span [44]: \"revolutionary\"   [− Labels: JJ (0.9998)]\n",
      "Span [45]: \"move\"   [− Labels: NN (1.0)]\n",
      "Span [46]: \"away\"   [− Labels: RB (0.9998)]\n",
      "Span [47]: \"from\"   [− Labels: IN (1.0)]\n",
      "Span [48]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [49]: \"Greek\"   [− Labels: JJ (0.5932)]\n",
      "Span [50]: \"concept\"   [− Labels: NN (1.0)]\n",
      "Span [51]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [52]: \"mathematics\"   [− Labels: NNS (0.997)]\n",
      "Span [53]: \"which\"   [− Labels: WDT (1.0)]\n",
      "Span [54]: \"was\"   [− Labels: VBD (1.0)]\n",
      "Span [55]: \"essentially\"   [− Labels: RB (1.0)]\n",
      "Span [56]: \"geometry\"   [− Labels: NN (0.9339)]\n",
      "Span [57]: \".\"   [− Labels: , (0.9943)]\n",
      "Span [58]: \"Algebra\"   [− Labels: NNP (0.9994)]\n",
      "Span [59]: \"was\"   [− Labels: VBD (1.0)]\n",
      "Span [60]: \"a\"   [− Labels: DT (1.0)]\n",
      "Span [61]: \"unifying\"   [− Labels: VBG (0.9965)]\n",
      "Span [62]: \"theory\"   [− Labels: NN (1.0)]\n",
      "Span [63]: \"which\"   [− Labels: WDT (1.0)]\n",
      "Span [64]: \"allowed\"   [− Labels: VBD (1.0)]\n",
      "Span [65]: \"rational\"   [− Labels: JJ (1.0)]\n",
      "Span [66]: \"numbers\"   [− Labels: NNS (1.0)]\n",
      "Span [67]: \",\"   [− Labels: , (1.0)]\n",
      "Span [68]: \"irrational\"   [− Labels: JJ (1.0)]\n",
      "Span [69]: \"numbers\"   [− Labels: NNS (1.0)]\n",
      "Span [70]: \",\"   [− Labels: , (1.0)]\n",
      "Span [71]: \"geometrical\"   [− Labels: JJ (0.9797)]\n",
      "Span [72]: \"magnitudes,etc.\"   [− Labels: NN (0.995)]\n",
      "Span [73]: \",\"   [− Labels: , (1.0)]\n",
      "Span [74]: \"to\"   [− Labels: TO (0.9955)]\n",
      "Span [75]: \"all\"   [− Labels: DT (0.8829)]\n",
      "Span [76]: \"be\"   [− Labels: VB (1.0)]\n",
      "Span [77]: \"treated\"   [− Labels: VBN (1.0)]\n",
      "Span [78]: \"as\"   [− Labels: IN (0.9999)]\n",
      "Span [79]: \"\"\"   [− Labels: `` (1.0)]\n",
      "Span [80]: \"algebraic\"   [− Labels: JJ (0.9999)]\n",
      "Span [81]: \"objects\"   [− Labels: NNS (0.9999)]\n",
      "Span [82]: \"\"\"   [− Labels: '' (1.0)]\n",
      "Span [83]: \".\"   [− Labels: , (1.0)]\n",
      "Span [84]: \"It\"   [− Labels: PRP (1.0)]\n",
      "Span [85]: \"gave\"   [− Labels: VBD (1.0)]\n",
      "Span [86]: \"mathematics\"   [− Labels: NNS (0.9994)]\n",
      "Span [87]: \"a\"   [− Labels: DT (1.0)]\n",
      "Span [88]: \"whole\"   [− Labels: JJ (0.9997)]\n",
      "Span [89]: \"new\"   [− Labels: JJ (1.0)]\n",
      "Span [90]: \"development\"   [− Labels: NN (1.0)]\n",
      "Span [91]: \"path\"   [− Labels: NN (1.0)]\n",
      "Span [92]: \"so\"   [− Labels: RB (0.9998)]\n",
      "Span [93]: \"much\"   [− Labels: RB (0.9917)]\n",
      "Span [94]: \"broader\"   [− Labels: JJR (0.9993)]\n",
      "Span [95]: \"in\"   [− Labels: IN (1.0)]\n",
      "Span [96]: \"concept\"   [− Labels: NN (1.0)]\n",
      "Span [97]: \"to\"   [− Labels: IN (1.0)]\n",
      "Span [98]: \"that\"   [− Labels: DT (0.9922)]\n",
      "Span [99]: \"which\"   [− Labels: WDT (1.0)]\n",
      "Span [100]: \"had\"   [− Labels: VBD (1.0)]\n",
      "Span [101]: \"existed\"   [− Labels: VBN (1.0)]\n",
      "Span [102]: \"before\"   [− Labels: RB (0.996)]\n",
      "Span [103]: \",\"   [− Labels: , (1.0)]\n",
      "Span [104]: \"and\"   [− Labels: CC (1.0)]\n",
      "Span [105]: \"provided\"   [− Labels: VBD (0.7769)]\n",
      "Span [106]: \"a\"   [− Labels: DT (1.0)]\n",
      "Span [107]: \"vehicle\"   [− Labels: NN (1.0)]\n",
      "Span [108]: \"for\"   [− Labels: IN (1.0)]\n",
      "Span [109]: \"future\"   [− Labels: JJ (0.9911)]\n",
      "Span [110]: \"development\"   [− Labels: NN (1.0)]\n",
      "Span [111]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [112]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [113]: \"subject\"   [− Labels: NN (0.9991)]\n",
      "Span [114]: \".\"   [− Labels: , (0.9996)]\n",
      "Span [115]: \"Another\"   [− Labels: DT (1.0)]\n",
      "Span [116]: \"important\"   [− Labels: JJ (1.0)]\n",
      "Span [117]: \"aspect\"   [− Labels: NN (1.0)]\n",
      "Span [118]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [119]: \"the\"   [− Labels: DT (1.0)]\n",
      "Span [120]: \"introduction\"   [− Labels: NN (1.0)]\n",
      "Span [121]: \"of\"   [− Labels: IN (1.0)]\n",
      "Span [122]: \"algebraic\"   [− Labels: JJ (1.0)]\n",
      "Span [123]: \"ideas\"   [− Labels: NNS (1.0)]\n",
      "Span [124]: \"was\"   [− Labels: VBD (1.0)]\n",
      "Span [125]: \"that\"   [− Labels: IN (0.9998)]\n",
      "Span [126]: \"it\"   [− Labels: PRP (1.0)]\n",
      "Span [127]: \"allowed\"   [− Labels: VBD (1.0)]\n",
      "Span [128]: \"mathematics\"   [− Labels: NNS (0.9994)]\n",
      "Span [129]: \"to\"   [− Labels: TO (1.0)]\n",
      "Span [130]: \"be\"   [− Labels: VB (1.0)]\n",
      "Span [131]: \"applied\"   [− Labels: VBN (1.0)]\n",
      "Span [132]: \"to\"   [− Labels: IN (1.0)]\n",
      "Span [133]: \"itself\"   [− Labels: PRP (1.0)]\n",
      "Span [134]: \"in\"   [− Labels: IN (1.0)]\n",
      "Span [135]: \"a\"   [− Labels: DT (1.0)]\n",
      "Span [136]: \"way\"   [− Labels: NN (1.0)]\n",
      "Span [137]: \"which\"   [− Labels: WDT (1.0)]\n",
      "Span [138]: \"had\"   [− Labels: VBD (1.0)]\n",
      "Span [139]: \"not\"   [− Labels: RB (1.0)]\n",
      "Span [140]: \"happened\"   [− Labels: VBN (0.9997)]\n",
      "Span [141]: \"before\"   [− Labels: RB (0.9824)]\n",
      "Span [142]: \".\"   [− Labels: . (1.0)]\n"
     ]
    }
   ],
   "source": [
    "##IMPORT MODULES\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "\n",
    "tags = SequenceTagger.load('flair/pos-english')\n",
    "my_sent = Sentence(english_text)\n",
    "tags.predict(my_sent)\n",
    "\n",
    "for w in my_sent.get_spans('pos'):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84042612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-20 21:45:12,039 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
      "[Sentence: \"\"   [− Tokens: 0],\n",
      " Sentence: \"Perhaps one of the most significant advances made by Arabic mathematics began at this time\"   [− Tokens: 15],\n",
      " Sentence: \"with the work of al-Khwarizmi , namely the beginnings of algebra .\"   [− Tokens: 12],\n",
      " Sentence: \"It is important to\"   [− Tokens: 4],\n",
      " Sentence: \"understand just how significant this new idea was .\"   [− Tokens: 9],\n",
      " Sentence: \"It was a revolutionary move away\"   [− Tokens: 6],\n",
      " Sentence: \"from the Greek concept of mathematics which was essentially geometry .\"   [− Tokens: 11],\n",
      " Sentence: \"Algebra was a\"   [− Tokens: 3],\n",
      " Sentence: \"unifying theory which allowed rational numbers , irrational numbers , geometrical\"   [− Tokens: 11],\n",
      " Sentence: \"magnitudes,etc. , to all be treated as \" algebraic objects \" .\"   [− Tokens: 12],\n",
      " Sentence: \"It gave mathematics a whole new\"   [− Tokens: 6],\n",
      " Sentence: \"development path so much broader in concept to that which had existed before , and provided a\"   [− Tokens: 17],\n",
      " Sentence: \"vehicle for future development of the subject .\"   [− Tokens: 8],\n",
      " Sentence: \"Another important aspect of the introduction\"   [− Tokens: 6],\n",
      " Sentence: \"of algebraic ideas was that it allowed mathematics to be applied to itself in a way which\"   [− Tokens: 17],\n",
      " Sentence: \"had not happened before .\"   [− Tokens: 5]]\n"
     ]
    }
   ],
   "source": [
    "#PRINT THE RESULT OF SENTENCE TOKENIZETION \n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "from segtok.segmenter import split_single\n",
    "sentences = [Sentence(sent, use_tokenizer=True) for sent in split_single(english_text)]\n",
    "\n",
    "pprint(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99472121",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#  Hugging face in Arab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed4aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#!pip install torch\n",
    "#!pip install pytorch_pretrained_bert\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5248e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "arab_text =(\"\"\"\n",
    "ربما كانت أحد أھم التطورات التي قامت بھا الریاضیات العربیة التي\n",
    "بدأت في ھذا الوقت بعمل الخوارزمي وھي بدایات الجبر، ومن المھم فھم كیف كانت ھذه الفكرة الجدیدة مھمة، فقد كانت خطوة ثوریة بعیدا عن المفھوم\n",
    "الیوناني للریاضیات التي ھي في جوھرھا ھندسة، الجبر كان نظریة موحدة تتیح الأعداد الكسریة والأعداد اللا كسریة، والمقادیر الھندسیة وغیرھا،\n",
    "أن تتعامل على أنھا أجسام جبریة، وأعطت الریاضیات ككل مسارا جدیدا للتطور بمفھوم أوسع بكثیر من الذي كان موجودا من قبل، وقدم وسیلة\n",
    "للتنمیة في ھذا الموضوع مستقبلا. وجانب آخر مھم لإدخال أفكار الجبر وھو أنھ سمح بتطبیق الریاضیات على نفسھا بطریقة لم تحدث من قبل\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a09a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ر', '##ب', '##م', '##ا', 'ك', '##ان', '##ت', 'أ', '##ح', '##د', '[UNK]', 'ا', '##ل', '##ت', '##ط', '##و', '##ر', '##ا', '##ت', 'ا', '##ل', '##ت', '##ي', 'ق', '##ا', '##م', '##ت', '[UNK]', 'ا', '##ل', '##ر', '##ی', '##ا', '##ض', '##ی', '##ا', '##ت', 'ا', '##ل', '##ع', '##ر', '##ب', '##ی', '##ة', 'ا', '##ل', '##ت', '##ي', 'ب', '##د', '##أ', '##ت', 'ف', '##ي', '[UNK]', 'ا', '##ل', '##و', '##ق', '##ت', 'ب', '##ع', '##م', '##ل', 'ا', '##ل', '##خ', '##و', '##ا', '##ر', '##ز', '##م', '##ي', '[UNK]', 'ب', '##د', '##ا', '##ی', '##ا', '##ت', 'ا', '##ل', '##ج', '##ب', '##ر', '،', 'و', '##م', '##ن', '[UNK]', '[UNK]', 'ك', '##ی', '##ف', 'ك', '##ان', '##ت', '[UNK]', 'ا', '##ل', '##ف', '##ك', '##ر', '##ة', 'ا', '##ل', '##ج', '##د', '##ی', '##د', '##ة', '[UNK]', '،', 'ف', '##ق', '##د', 'ك', '##ان', '##ت', 'خ', '##ط', '##و', '##ة', 'ث', '##و', '##ر', '##ی', '##ة', 'ب', '##ع', '##ی', '##د', '##ا', 'ع', '##ن', '[UNK]', 'ا', '##ل', '##ی', '##و', '##ن', '##ان', '##ي', 'ل', '##ل', '##ر', '##ی', '##ا', '##ض', '##ی', '##ا', '##ت', 'ا', '##ل', '##ت', '##ي', '[UNK]', 'ف', '##ي', '[UNK]', '[UNK]', '،', 'ا', '##ل', '##ج', '##ب', '##ر', 'ك', '##ان', 'ن', '##ظ', '##ر', '##ی', '##ة', 'م', '##و', '##ح', '##د', '##ة', 'ت', '##ت', '##ی', '##ح', 'ا', '##ل', '##أ', '##ع', '##د', '##اد', 'ا', '##ل', '##ك', '##س', '##ر', '##ی', '##ة', 'و', '##ا', '##ل', '##أ', '##ع', '##د', '##اد', 'ا', '##ل', '##ل', '##ا', 'ك', '##س', '##ر', '##ی', '##ة', '،', 'و', '##ا', '##ل', '##م', '##ق', '##اد', '##ی', '##ر', '[UNK]', '[UNK]', '،', 'أ', '##ن', 'ت', '##ت', '##ع', '##ا', '##م', '##ل', 'ع', '##ل', '##ى', '[UNK]', 'أ', '##ج', '##س', '##ا', '##م', 'ج', '##ب', '##ر', '##ی', '##ة', '،', 'و', '##أ', '##ع', '##ط', '##ت', 'ا', '##ل', '##ر', '##ی', '##ا', '##ض', '##ی', '##ا', '##ت', 'ك', '##ك', '##ل', 'م', '##س', '##ا', '##ر', '##ا', 'ج', '##د', '##ی', '##د', '##ا', 'ل', '##ل', '##ت', '##ط', '##و', '##ر', '[UNK]', 'أ', '##و', '##س', '##ع', 'ب', '##ك', '##ث', '##ی', '##ر', 'م', '##ن', 'ا', '##ل', '##ذ', '##ي', 'ك', '##ان', 'م', '##و', '##ج', '##و', '##د', '##ا', 'م', '##ن', 'ق', '##ب', '##ل', '،', 'و', '##ق', '##د', '##م', 'و', '##س', '##ی', '##ل', '##ة', 'ل', '##ل', '##ت', '##ن', '##م', '##ی', '##ة', 'ف', '##ي', '[UNK]', 'ا', '##ل', '##م', '##و', '##ض', '##و', '##ع', 'م', '##س', '##ت', '##ق', '##ب', '##ل', '##ا', '.', 'و', '##ج', '##ان', '##ب', 'آ', '##خ', '##ر', '[UNK]', 'ل', '##إ', '##د', '##خ', '##ا', '##ل', 'أ', '##ف', '##ك', '##ا', '##ر', 'ا', '##ل', '##ج', '##ب', '##ر', '[UNK]', '[UNK]', 'س', '##م', '##ح', 'ب', '##ت', '##ط', '##ب', '##ی', '##ق', 'ا', '##ل', '##ر', '##ی', '##ا', '##ض', '##ی', '##ا', '##ت', 'ع', '##ل', '##ى', '[UNK]', 'ب', '##ط', '##ر', '##ی', '##ق', '##ة', 'ل', '##م', 'ت', '##ح', '##د', '##ث', 'م', '##ن', 'ق', '##ب', '##ل']\n"
     ]
    }
   ],
   "source": [
    "#TOKENIZETION OF TEXT\n",
    "\n",
    "MODEL_NAME = ('bert-base-cased')\n",
    "\n",
    "token = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "token3 = token.tokenize(arab_text)\n",
    "\n",
    "#PRINT OF TOKENIZETION\n",
    "\n",
    "print(token3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "229c34d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-20 21:45:15,470 --------------------------------------------------------------------------------\n",
      "2021-07-20 21:45:15,474 The model key 'pos-multi' now maps to 'https://huggingface.co/flair/upos-multi' on the HuggingFace ModelHub\n",
      "2021-07-20 21:45:15,478  - The most current version of the model is automatically downloaded from there.\n",
      "2021-07-20 21:45:15,479  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/multi-pos/pos-multi-v0.1.pt)\n",
      "2021-07-20 21:45:15,488 --------------------------------------------------------------------------------\n",
      "2021-07-20 21:45:16,708 loading file /Users/danieljoaquimpaulino/.flair/models/upos-multi/1a44f168663182024fd3ea6d7dcaeee47fe5bcb537cc737ad058b64ad4db9736.5f899f25846741510a6567b89027d988bd6f634b2776a7c3e834fea4629367cb\n"
     ]
    }
   ],
   "source": [
    "#IMPORT MODULES\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "#POS TAGGING\n",
    "\n",
    "tags3 = SequenceTagger.load('pos-multi')\n",
    "my_sent3 = Sentence(arab_text)\n",
    "tags3.predict(my_sent3)\n",
    "\n",
    "for w in my_sent3.get_spans('pos'):\n",
    "    \n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91431562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
